## Задание 1

Составьте постмотрем, на основе реального сбоя системы Github в 2018 году.

Информация о сбое доступна [в виде краткой выжимки на русском языке](https://habr.com/ru/post/427301/) , а
также [развёрнуто на английском языке](https://github.blog/2018-10-30-oct21-post-incident-analysis/).

| Наименование | Описание |
| ------------ | -------- |
| Краткое описание | В 22:52 (21.10) по UTC на нескольких сервисах GitHub.com пострадали несколько сетевых разделов и последующим сбоем базы данных, что привело к появлению непоследовательной информации на нашем веб-сайте |
| Предшествующие события |21 октября в 22:52 UTC в результате регламентных работ по замене вышедшего из строя оптического оборудования 100G была потеряна связь между сетевым концентратором на восточном побережье США и основным центром обработки данных на восточном побережье США. Связь между этими точками была восстановлена ​​за 43 секунды, но этот кратковременный сбой вызвал цепочку событий, которые привели к ухудшению качества обслуживания на 24 часа 11 минут. |
| Причина инцидента | Серверы баз данных в центре обработки данных на восточном побережье США содержали короткий период записи, который не был реплицирован на объект на западном побережье США. Поскольку кластеры баз данных в обоих центрах обработки данных теперь содержали записи, которых не было в другом центре обработки данных, мы не смогли безопасно выполнить возврат основного сервера в центр обработки данных на восточном побережье США.|
| Воздействие | В течение этого времени информация, отображаемая на GitHub.com, скорее всего, будет устаревшей; однако данные не были потеряны. |
| Обнаружение | Внутренние системы мониторинга начали генерировать предупреждения, указывающие на многочисленные сбои в наших системах. В это время несколько инженеров отвечали и работали над сортировкой входящих уведомлений. |
| Реакция | UTC инженеры нашей группы быстрого реагирования определили, что топологии многочисленных кластеров баз данных находятся в непредвиденном состоянии. Запрос API Orchestrator показал топологию репликации базы данных, которая включала только серверы из нашего центра обработки данных на западном побережье США. Oтвечающая команда решила вручную заблокировать наш внутренний инструмент развертывания, чтобы предотвратить внесение каких-либо дополнительных изменений. В 23:09 по всемирному координированному времени команда респондентов поместила сайт в желтый статус . Это действие автоматически переводит ситуацию в активный инцидент и отправляет предупреждение координатору инцидентов. В 23:11 по всемирному координированному времени присоединился координатор инцидента и через две минуты изменил статус решения на красный . |
| Восстановление | восстановить из резервных копий, синхронизировать реплики на обоих сайтах, вернуться к стабильной топологии обслуживания, а затем возобновить обработку заданий в очереди. |
| Таймлайн | - 22:54 UTC - системы мониторинга начали генерировать предупреждения, указывающие на многочисленные сбои в наших системах - 21.10.18 23:02 UTC инженеры нашей группы быстрого реагирования определили, что топологии многочисленных кластеров баз данных находятся в непредвиденном состоянии  21.10.18 23:09 по всемирному координированному времени команда респондентов поместила сайт в желтый статус  21.10.18 23:11 по всемирному координированному времени присоединился координатор инцидента и через две минуты изменил статус решения на красный.  21.10.18 23:13 UTC - стало понятно, что проблема затронула несколько кластеров баз данных. Были вызваны дополнительные инженеры из группы разработки баз данных GitHub.  21.10.18 23:19 UTC - выработка стратегия заключалась в том, чтобы отдавать предпочтение целостности данных, а не удобству использования сайта и времени восстановления.  22.10.18 00:05 UTC - разработка плана по устранению несоответствий данных и внедрению наших процедур аварийного переключения для MySQL.  22.10.18 00:41 UTC - инициирован процесс резервного копирования для всех затронутых кластеров MySQL, и инженеры следили за его ходом.  22.10.18 06:51 UTC - Несколько кластеров завершили восстановление из резервных копий в нашем центре обработки данных на восточном побережье США и начали репликацию новых данных с западного побережья. Это привело к медленной загрузке сайта для страниц, которые должны были выполнить операцию записи по межстрановой ссылке, но страницы, читающие из этих кластеров баз данных, возвращали актуальные результаты, если запрос на чтение попадал на только что восстановленную реплику. Другие более крупные кластеры баз данных все еще восстанавливались.  22.10.18 07:46 UTC - GitHub опубликовал сообщение в блоге , чтобы предоставить больше контекста.  22.10.18 11:12 UTC - Все первичные базы данных снова установлены на восточном побережье США. Это привело к тому, что сайт стал гораздо более отзывчивым, так как записи теперь направлялись на сервер базы данных, расположенный в том же физическом центре обработки данных, что и наш уровень приложений. Несмотря на то, что это существенно повысило производительность, по-прежнему существовали десятки реплик чтения базы данных, которые отставали от основной на несколько часов.  22.10.18 13:15 UTC - К настоящему времени мы приближались к пиковой нагрузке трафика на GitHub.com. Группа реагирования на инциденты обсудила, как действовать дальше. Было ясно, что задержки репликации увеличиваются, а не уменьшаются в направлении согласованного состояния. Мы начали предоставлять дополнительные реплики чтения MySQL в общедоступном облаке восточного побережья США ранее во время инцидента. Как только они стали доступны, стало проще распределять объем запросов на чтение по большему количеству серверов. Сокращение совокупного использования реплик чтения позволило репликации наверстать упущенное.  22.10.18 16:24 UTC - Как только реплики были синхронизированы, мы выполнили аварийное переключение на исходную топологию, решив немедленные проблемы с задержкой/доступностью.  22.10.18 23:03 UTC - Все ожидающие сборки вебхуков и страниц были обработаны, и была подтверждена целостность и правильная работа всех систем. Статус сайта был обновлен до зеленого . |
| Последующие действия | Начнем системную практику проверки сценариев сбоев, прежде чем они смогут повлиять на вас. Эта работа потребует будущих инвестиций в инструменты внедрения ошибок и хаос-инжиниринга в GitHub. |