Приложение запущено и работает, но время от времени появляется необходимость передавать между бекендами данные. А сам бекенд генерирует статику для фронта. Нужно оптимизировать это.
Для настройки NFS сервера можно воспользоваться следующей инструкцией (производить под пользователем на сервере, у которого есть доступ до kubectl):
* установить helm: curl https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash
* добавить репозиторий чартов: helm repo add stable https://charts.helm.sh/stable && helm repo update
* установить nfs-server через helm: helm install nfs-server stable/nfs-server-provisioner

В конце установки будет выдан пример создания PVC для этого сервера.

```bash
lsd@nuc:~$ curl https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100 11156  100 11156    0     0  31874      0 --:--:-- --:--:-- --:--:-- 31874
WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /home/lsd/.kube/config
Helm v3.10.2 is available. Changing from version v3.9.4.
Downloading https://get.helm.sh/helm-v3.10.2-linux-amd64.tar.gz
Verifying checksum... Done.
Preparing to install helm into /usr/local/bin
[sudo] password for lsd: 
helm installed into /usr/local/bin/helm
lsd@nuc:~$ helm repo add stable https://charts.helm.sh/stable && helm repo update
WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /home/lsd/.kube/config
"stable" has been added to your repositories
WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /home/lsd/.kube/config
Hang tight while we grab the latest from your chart repositories...
...Successfully got an update from the "stable" chart repository
Update Complete. ⎈Happy Helming!⎈
lsd@nuc:~$ helm install nfs-server stable/nfs-server-provisioner
WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /home/lsd/.kube/config
WARNING: This chart is deprecated
NAME: nfs-server
LAST DEPLOYED: Tue Nov 22 10:26:17 2022
NAMESPACE: default
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
The NFS Provisioner service has now been installed.

A storage class named 'nfs' has now been created
and is available to provision dynamic volumes.

You can use this storageclass by creating a `PersistentVolumeClaim` with the
correct storageClassName attribute. For example:

    ---
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
    name: test-dynamic-volume-claim
spec:
    storageClassName: "nfs"
    accessModes:
    - ReadWriteOnce
    resources:
    requests:
        storage: 100Mi
```

```bash
lsd@nuc:~$ kubectl create namespace stage
namespace/stage created
lsd@nuc:~$ kubectl create namespace prod
namespace/prod created
lsd@nuc:~$ kubectl get namespace -A
NAME              STATUS   AGE
kube-system       Active   24h
kube-public       Active   24h
kube-node-lease   Active   24h
default           Active   24h
stage             Active   10s
prod              Active   4s
```

## Задание 1: подключить для тестового конфига общую папку
В stage окружении часто возникает необходимость отдавать статику бекенда сразу фронтом. Проще всего сделать это через общую папку. Требования:
* в поде подключена общая папка между контейнерами (например, /static);
* после записи чего-либо в контейнере с беком файлы можно получить из контейнера с фронтом.

```bash
lsd@nuc:~$ kubectl apply -n stage -f kube_storage/pod-int-volumes.yaml
pod/pod-int-volumes created
lsd@nuc:~$ kubectl get -n stage pods
NAME              READY   STATUS    RESTARTS   AGE
pod-int-volumes   2/2     Running   0          2m43s
```

Создаем файл в контейнере nginx и проверяем наличие файла файлы в контейнере busybox:

```bash
lsd@nuc:~$ kubectl -n stage exec pod-int-volumes -c nginx -- sh -c "echo 'test' > /static/test.txt"
lsd@nuc:~$ kubectl -n stage exec pod-int-volumes -c nginx -- ls -la /static
total 12
drwxrwxrwx 2 root root 4096 Nov 22 08:40 .
drwxr-xr-x 1 root root 4096 Nov 22 08:36 ..
-rw-r--r-- 1 root root    5 Nov 22 08:40 test.txt
lsd@nuc:~$ kubectl -n stage exec pod-int-volumes -c nginx -- cat /static/test.txt
test
lsd@nuc:~$ kubectl -n stage exec pod-int-volumes -c busybox -- ls -la /tmp/cache
total 12
drwxrwxrwx    2 root     root          4096 Nov 22 08:40 .
drwxrwxrwt    1 root     root          4096 Nov 22 08:36 ..
-rw-r--r--    1 root     root             5 Nov 22 08:40 test.txt
lsd@nuc:~$ kubectl -n stage exec pod-int-volumes -c busybox -- cat /tmp/cache/test.txt
test
```

Создаем файл в контейнере busybox и проверяем наличие файла в контейнере nginx:

```bash
lsd@nuc:~$ kubectl -n stage exec pod-int-volumes -c busybox -- touch /tmp/cache/test2.txt
lsd@nuc:~$ kubectl -n stage exec pod-int-volumes -c nginx -- ls -la /static
total 12
drwxrwxrwx 2 root root 4096 Nov 22 08:47 .
drwxr-xr-x 1 root root 4096 Nov 22 08:36 ..
-rw-r--r-- 1 root root    5 Nov 22 08:40 test.txt
-rw-r--r-- 1 root root    0 Nov 22 08:47 test2.txt
```


## Задание 2: подключить общую папку для прода
Поработав на stage, доработки нужно отправить на прод. В продуктиве у нас контейнеры крутятся в разных подах, поэтому потребуется PV и связь через PVC. Сам PV должен быть связан с NFS сервером. Требования:
* все бекенды подключаются к одному PV в режиме ReadWriteMany;
* фронтенды тоже подключаются к этому же PV с таким же режимом;
* файлы, созданные бекендом, должны быть доступны фронту.

```bash
lsd@nuc:~$ kubectl get sc
NAME   PROVISIONER                                       RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE
nfs    cluster.local/nfs-server-nfs-server-provisioner   Delete          Immediate           true                   5h21m
lsd@nuc:~$ kubectl get csinodes
NAME   DRIVERS   AGE
nuc    0         29h
lsd@nuc:~$ microk8s status
microk8s is running
high-availability: no
  datastore master nodes: 127.0.0.1:19001
  datastore standby nodes: none
addons:
  enabled:
    ha-cluster           # (core) Configure high availability on the current node
    helm                 # (core) Helm - the package manager for Kubernetes
    helm3                # (core) Helm 3 - the package manager for Kubernetes
    hostpath-storage     # (core) Storage class; allocates storage from host directory
    storage              # (core) Alias to hostpath-storage add-on, deprecated
  disabled:
    cert-manager         # (core) Cloud native certificate management
    community            # (core) The community addons repository
    dashboard            # (core) The Kubernetes dashboard
    dns                  # (core) CoreDNS
    gpu                  # (core) Automatic enablement of Nvidia CUDA
    host-access          # (core) Allow Pods connecting to Host services smoothly
    ingress              # (core) Ingress controller for external access
    kube-ovn             # (core) An advanced network fabric for Kubernetes
    mayastor             # (core) OpenEBS MayaStor
    metallb              # (core) Loadbalancer for your Kubernetes cluster
    metrics-server       # (core) K8s Metrics Server for API access to service metrics
    observability        # (core) A lightweight observability stack for logs, traces and metrics
    prometheus           # (core) Prometheus operator for monitoring and logging
    rbac                 # (core) Role-Based Access Control for authorisation
    registry             # (core) Private image registry exposed on localhost:32000
```

```bash
Every 2.0s: kubectl get po,pvc,pv                                                                                                                                                                                              nuc: Tue Nov 22 16:49:19 2022
NAME                                      READY   STATUS    RESTARTS       AGE
pod/nfs-server-nfs-server-provisioner-0   1/1     Running   1 (128m ago)   6h23m
pod/pod                                   1/1     Running   0              16m
pod/front                                 1/1     Running   0              2m36s
pod/back                                  1/1     Running   0              2m30s

NAME                                              STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
persistentvolumeclaim/test-dynamic-volume-claim   Bound    pvc-46d7a7d2-6421-4782-94d4-6766241f8156   2Gi        RWO            nfs            21m

NAME                                                        CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                               STORAGECLASS   REASON   AGE
persistentvolume/pvc-46d7a7d2-6421-4782-94d4-6766241f8156   2Gi        RWO            Delete           Bound    default/test-dynamic-volume-claim   nfs                     21m
```

```bash
lsd@nuc:~$ kubectl apply -f kube_storage/front.yaml
pod/front created
lsd@nuc:~$ kubectl apply -f kube_storage/back.yaml
pod/back created
lsd@nuc:~$ kubectl exec front -- ls -la /static
total 12
drwxrwsrwx 2 root root 4096 Nov 22 13:34 .
drwxr-xr-x 1 root root 4096 Nov 22 13:46 ..
-rw-r--r-- 1 root root    8 Nov 22 13:34 dynamic.txt
lsd@nuc:~$ kubectl exec front -- sh -c "echo 'dynamic' > /static/front.txt"
lsd@nuc:~$ kubectl exec front -- ls -la /static
total 16
drwxrwsrwx 2 root root 4096 Nov 22 13:47 .
drwxr-xr-x 1 root root 4096 Nov 22 13:46 ..
-rw-r--r-- 1 root root    8 Nov 22 13:34 dynamic.txt
-rw-r--r-- 1 root root    8 Nov 22 13:47 front.txt
lsd@nuc:~$ kubectl exec back -- ls -la /static
total 16
drwxrwsrwx 2 root root 4096 Nov 22 13:47 .
drwxr-xr-x 1 root root 4096 Nov 22 13:46 ..
-rw-r--r-- 1 root root    8 Nov 22 13:34 dynamic.txt
-rw-r--r-- 1 root root    8 Nov 22 13:47 front.txt
lsd@nuc:~$ kubectl exec back -- sh -c "echo 'dynamic' > /static/back.txt"
lsd@nuc:~$ kubectl exec back -- ls -la /static
total 20
drwxrwsrwx 2 root root 4096 Nov 22 13:48 .
drwxr-xr-x 1 root root 4096 Nov 22 13:46 ..
-rw-r--r-- 1 root root    8 Nov 22 13:48 back.txt
-rw-r--r-- 1 root root    8 Nov 22 13:34 dynamic.txt
-rw-r--r-- 1 root root    8 Nov 22 13:47 front.txt
```

```bash
lsd@nuc:~/kube_storage$ cat pvc.yaml
apiVersion: v1
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
    name: test-dynamic-volume-claim
spec:
    storageClassName: "nfs"
    accessModes:
    - ReadWriteOnce
    resources:
      requests:
        storage: 2Gi
```

```bash
lsd@nuc:~/kube_storage$ cat front.yaml
apiVersion: v1
kind: Pod
metadata:
  name: front
spec:
  containers:
    - name: nginx
      image: nginx
      volumeMounts:
        - mountPath: "/static"
          name: test-dynamic-volume-claim
  volumes:
    - name: test-dynamic-volume-claim
      persistentVolumeClaim:
        claimName: test-dynamic-volume-claim
```