1. Узнайте о [sparse](https://ru.wikipedia.org/wiki/%D0%A0%D0%B0%D0%B7%D1%80%D0%B5%D0%B6%D1%91%D0%BD%D0%BD%D1%8B%D0%B9_%D1%84%D0%B0%D0%B9%D0%BB) (разряженных) файлах.

```bash
lsd@Virtual-Machine:~$ dd if=/dev/zero of=file-sparse bs=1 count=0 seek=2G

0+0 записей получено

0+0 записей отправлено

0 байт скопировано, 0,000303902 s, 0,0 kB/s

lsd@Virtual-Machine:~$ stat file-sparse

Файл: file-sparse

Размер: 2147483648 Блоков: 0 Блок В/В: 4096 обычный файл

Устройство: 801h/2049d Инода: 1041891 Ссылки: 1

Доступ: (0664/-rw-rw-r--) Uid: ( 1000/ lsd) Gid: ( 1000/ lsd)

Доступ: 2022-02-18 11:14:49.767639245 +0300

Модифицирован: 2022-02-18 11:14:13.695411434 +0300

Изменён: 2022-02-18 11:14:13.695411434 +0300

Создан: -
```

2. Могут ли файлы, являющиеся жесткой ссылкой на один объект, иметь разные права доступа и владельца? Почему?

Нет, не могут, т.к. это просто ссылки на один и тот же `inode` - в нём и хранятся права доступа и имя владельца.

3. Сделайте `vagrant destroy` на имеющийся инстанс Ubuntu. Замените содержимое Vagrantfile следующим:

    ```bash
    Vagrant.configure("2") do |config|
      config.vm.box = "bento/ubuntu-20.04"
      config.vm.provider :virtualbox do |vb|
        lvm_experiments_disk0_path = "/tmp/lvm_experiments_disk0.vmdk"
        lvm_experiments_disk1_path = "/tmp/lvm_experiments_disk1.vmdk"
        vb.customize ['createmedium', '--filename', lvm_experiments_disk0_path, '--size', 2560]
        vb.customize ['createmedium', '--filename', lvm_experiments_disk1_path, '--size', 2560]
        vb.customize ['storageattach', :id, '--storagectl', 'SATA Controller', '--port', 1, '--device', 0, '--type', 'hdd', '--medium', lvm_experiments_disk0_path]
        vb.customize ['storageattach', :id, '--storagectl', 'SATA Controller', '--port', 2, '--device', 0, '--type', 'hdd', '--medium', lvm_experiments_disk1_path]
      end
    end
    ```

Данная конфигурация создаст новую виртуальную машину с двумя дополнительными неразмеченными дисками по 2.5 Гб.

```bash
vagrant@vagrant:~$ lsblk

NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT

loop0 7:0 0 55.4M 1 loop /snap/core18/2128

loop2 7:2 0 70.3M 1 loop /snap/lxd/21029

loop3 7:3 0 55.5M 1 loop /snap/core18/2284

loop4 7:4 0 43.6M 1 loop /snap/snapd/14978

loop5 7:5 0 61.9M 1 loop /snap/core20/1328

loop6 7:6 0 67.2M 1 loop /snap/lxd/21835

sda 8:0 0 64G 0 disk

├─sda1 8:1 0 1M 0 part

├─sda2 8:2 0 1G 0 part /boot

└─sda3 8:3 0 63G 0 part

└─ubuntu--vg-ubuntu--lv 253:0 0 31.5G 0 lvm /

sdb 8:16 0 2.5G 0 disk

sdc 8:32 0 2.5G 0 disk
```

4. Используя `fdisk`, разбейте первый диск на 2 раздела: 2 Гб, оставшееся пространство.

```bash
vagrant@vagrant:~$ sudo fdisk /dev/sdb

Welcome to fdisk (util-linux 2.34).

Changes will remain in memory only, until you decide to write them.

Be careful before using the write command.

Device does not contain a recognized partition table.

Created a new DOS disklabel with disk identifier 0x4b4215ec.

Command (m for help): F

Unpartitioned space /dev/sdb: 2.51 GiB, 2683305984 bytes, 5240832 sectors

Units: sectors of 1 * 512 = 512 bytes

Sector size (logical/physical): 512 bytes / 512 bytes

Start End Sectors Size

2048 5242879 5240832 2.5G

Command (m for help): n

Partition type

p primary (0 primary, 0 extended, 4 free)

e extended (container for logical partitions)

Select (default p): p

Partition number (1-4, default 1):

First sector (2048-5242879, default 2048):

Last sector, +/-sectors or +/-size{K,M,G,T,P} (2048-5242879, default 5242879): +2G

Created a new partition 1 of type 'Linux' and of size 2 GiB.

Command (m for help): n

Partition type

p primary (1 primary, 0 extended, 3 free)

e extended (container for logical partitions)

Select (default p): p

Partition number (2-4, default 2):

First sector (4196352-5242879, default 4196352):

Last sector, +/-sectors or +/-size{K,M,G,T,P} (4196352-5242879, default 5242879):

Created a new partition 2 of type 'Linux' and of size 511 MiB.

Command (m for help): w

The partition table has been altered.

Calling ioctl() to re-read partition table.

Syncing disks.
```

5. Используя `sfdisk`, перенесите данную таблицу разделов на второй диск.

```bash
vagrant@vagrant:~$ sudo sfdisk -d /dev/sdb > sdb

vagrant@vagrant:~$ cat sdb

label: dos

label-id: 0x4b4215ec

device: /dev/sdb

unit: sectors

/dev/sdb1 : start= 2048, size= 4194304, type=83

/dev/sdb2 : start= 4196352, size= 1046528, type=83

vagrant@vagrant:~$ sudo sfdisk /dev/sdc < sdb

Checking that no-one is using this disk right now ... OK

Disk /dev/sdc: 2.51 GiB, 2684354560 bytes, 5242880 sectors

Disk model: VBOX HARDDISK

Units: sectors of 1 * 512 = 512 bytes

Sector size (logical/physical): 512 bytes / 512 bytes

I/O size (minimum/optimal): 512 bytes / 512 bytes

Script header accepted.

Script header accepted.

Script header accepted.

Script header accepted.

Created a new DOS disklabel with disk identifier 0x4b4215ec.

/dev/sdc1: Created a new partition 1 of type 'Linux' and of size 2 GiB.

/dev/sdc2: Created a new partition 2 of type 'Linux' and of size 511 MiB.

/dev/sdc3: Done.

New situation:

Disklabel type: dos

Disk identifier: 0x4b4215ec

Device Boot Start End Sectors Size Id Type

/dev/sdc1 2048 4196351 4194304 2G 83 Linux

/dev/sdc2 4196352 5242879 1046528 511M 83 Linux

The partition table has been altered.

Calling ioctl() to re-read partition table.

Syncing disks.

vagrant@vagrant:~$ lsblk

NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT

loop0 7:0 0 55.4M 1 loop /snap/core18/2128

loop2 7:2 0 70.3M 1 loop /snap/lxd/21029

loop3 7:3 0 55.5M 1 loop /snap/core18/2284

loop4 7:4 0 43.6M 1 loop /snap/snapd/14978

loop5 7:5 0 61.9M 1 loop /snap/core20/1328

loop6 7:6 0 67.2M 1 loop /snap/lxd/21835

sda 8:0 0 64G 0 disk

├─sda1 8:1 0 1M 0 part

├─sda2 8:2 0 1G 0 part /boot

└─sda3 8:3 0 63G 0 part

└─ubuntu--vg-ubuntu--lv 253:0 0 31.5G 0 lvm /

sdb 8:16 0 2.5G 0 disk

├─sdb1 8:17 0 2G 0 part

└─sdb2 8:18 0 511M 0 part

sdc 8:32 0 2.5G 0 disk

├─sdc1 8:33 0 2G 0 part

└─sdc2 8:34 0 511M 0 part
```

6. Соберите `mdadm` RAID1 на паре разделов 2 Гб.

```bash
grant@vagrant:~$ mdadm --create /dev/md0 --level=1 --raid-devices=2 /dev/sdb1 /dev/sdc1

mdadm: must be super-user to perform this action

vagrant@vagrant:~$ sudo mdadm --create /dev/md0 --level=1 --raid-devices=2 /dev/sdb1 /dev/sdc1

mdadm: Note: this array has metadata at the start and

may not be suitable as a boot device.  If you plan to

store '/boot' on this device please ensure that

your boot-loader understands md/v1.x metadata, or use

--metadata=0.90
Continue creating array? y

mdadm: Defaulting to version 1.2 metadata

mdadm: array /dev/md0 started.

vagrant@vagrant:~$ lsblk

NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT

loop0 7:0 0 55.4M 1 loop /snap/core18/2128

loop2 7:2 0 70.3M 1 loop /snap/lxd/21029

loop3 7:3 0 55.5M 1 loop /snap/core18/2284

loop4 7:4 0 43.6M 1 loop /snap/snapd/14978

loop5 7:5 0 61.9M 1 loop /snap/core20/1328

loop6 7:6 0 67.2M 1 loop /snap/lxd/21835

sda 8:0 0 64G 0 disk

├─sda1 8:1 0 1M 0 part

├─sda2 8:2 0 1G 0 part /boot

└─sda3 8:3 0 63G 0 part

└─ubuntu--vg-ubuntu--lv 253:0 0 31.5G 0 lvm /

sdb 8:16 0 2.5G 0 disk

├─sdb1 8:17 0 2G 0 part

│ └─md0 9:0 0 2G 0 raid1

└─sdb2 8:18 0 511M 0 part

sdc 8:32 0 2.5G 0 disk

├─sdc1 8:33 0 2G 0 part

│ └─md0 9:0 0 2G 0 raid1

└─sdc2 8:34 0 511M 0 part
```

7. Соберите `mdadm` RAID0 на второй паре маленьких разделов.

```bash
vagrant@vagrant:~$ sudo mdadm --create /dev/md1 --level=0 --raid-devices=2 /dev/sdb2 /dev/sdc2

mdadm: Defaulting to version 1.2 metadata

mdadm: array /dev/md1 started.

vagrant@vagrant:~$ lsblk

NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT

loop0 7:0 0 55.4M 1 loop /snap/core18/2128

loop2 7:2 0 70.3M 1 loop /snap/lxd/21029

loop3 7:3 0 55.5M 1 loop /snap/core18/2284

loop4 7:4 0 43.6M 1 loop /snap/snapd/14978

loop5 7:5 0 61.9M 1 loop /snap/core20/1328

loop6 7:6 0 67.2M 1 loop /snap/lxd/21835

sda 8:0 0 64G 0 disk

├─sda1 8:1 0 1M 0 part

├─sda2 8:2 0 1G 0 part /boot

└─sda3 8:3 0 63G 0 part

└─ubuntu--vg-ubuntu--lv 253:0 0 31.5G 0 lvm /

sdb 8:16 0 2.5G 0 disk

├─sdb1 8:17 0 2G 0 part

│ └─md0 9:0 0 2G 0 raid1

└─sdb2 8:18 0 511M 0 part

└─md1 9:1 0 1018M 0 raid0

sdc 8:32 0 2.5G 0 disk

├─sdc1 8:33 0 2G 0 part

│ └─md0 9:0 0 2G 0 raid1

└─sdc2 8:34 0 511M 0 part

└─md1 9:1 0 1018M 0 raid0
```

8. Создайте 2 независимых PV на получившихся md-устройствах.

```bash
vagrant@vagrant:~$ sudo pvcreate /dev/md0

Physical volume "/dev/md0" successfully created.

vagrant@vagrant:~$ sudo pvcreate /dev/md1

Physical volume "/dev/md1" successfully created.
```

9. Создайте общую `volume-group` на этих двух `PV`.

```bash
vagrant@vagrant:~$ sudo vgcreate netology /dev/md0 /dev/md1

Volume group "netology" successfully created

vagrant@vagrant:~$ sudo vgs

VG #PV #LV #SN Attr VSize VFree

netology 2 0 0 wz--n- <2.99g <2.99g

ubuntu-vg 1 1 0 wz--n- <63.00g <31.50g
```

10. Создайте `LV` размером 100 Мб, указав его расположение на `PV` с RAID0.

```bash
vagrant@vagrant:~$ sudo lvcreate -L 100m -n netology-lv netology /dev/md1

Logical volume "netology-lv" created.

vagrant@vagrant:~$ sudo lvs -o +devices

LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert Devices

netology-lv netology -wi-a----- 100.00m /dev/md1(0)

ubuntu-lv ubuntu-vg -wi-ao---- 31.50g /dev/sda3(0)
```

11. Создайте `mkfs.ext4` ФС на получившемся `LV`.

```bash
vagrant@vagrant:~$ sudo mkfs.ext4 -L netology-ext4 -m 1 /dev/mapper/netology-netology--lv

mke2fs 1.45.5 (07-Jan-2020)

Creating filesystem with 25600 4k blocks and 25600 inodes

Allocating group tables: done

Writing inode tables: done

Creating journal (1024 blocks): done

Writing superblocks and filesystem accounting information: done

vagrant@vagrant:~$ sudo blkid | grep netology-netology--lv

/dev/mapper/netology-netology--lv: LABEL="netology-ext4" UUID="cbdf93dc-7fab-4ccc-85d6-eee177bdffd6" TYPE="ext4"
```

12. Смонтируйте этот раздел в любую директорию, например, `/tmp/new`.

```bash
vagrant@vagrant:~$ sudo blkid | grep netology-netology--lv

/dev/mapper/netology-netology--lv: LABEL="netology-ext4" UUID="cbdf93dc-7fab-4ccc-85d6-eee177bdffd6" TYPE="ext4"

vagrant@vagrant:~$ sudo mkdir /tmp/new

vagrant@vagrant:~$ sudo mount /dev/mapper/netology-netology--lv /tmp/new/

vagrant@vagrant:~$ sudo mount | grep netology-netology--lv

/dev/mapper/netology-netology--lv on /tmp/new type ext4 (rw,relatime,stripe=256)
```

13. Поместите туда тестовый файл, например `wget https://mirror.yandex.ru/ubuntu/ls-lR.gz -O /tmp/new/test.gz`.

```bash
vagrant@vagrant:/tmp/new$ wget https://mirror.yandex.ru/ubuntu/ls-lR.gz -O /tmp/new/test.gz

/tmp/new/test.gz: Permission denied

vagrant@vagrant:/tmp/new$ sudo wget https://mirror.yandex.ru/ubuntu/ls-lR.gz -O /tmp/new/test.gz

--2022-02-18 20:07:48-- https://mirror.yandex.ru/ubuntu/ls-lR.gz

Resolving mirror.yandex.ru (mirror.yandex.ru)... 213.180.204.183, 2a02:6b8::183

Connecting to mirror.yandex.ru (mirror.yandex.ru)|213.180.204.183|:443... connected.

HTTP request sent, awaiting response... 200 OK

Length: 22346906 (21M) [application/octet-stream]

Saving to: ‘/tmp/new/test.gz’

/tmp/new/test.gz 100%[======================================================>] 21.31M 663KB/s in 34s

2022-02-18 20:08:23 (635 KB/s) - ‘/tmp/new/test.gz’ saved [22346906/22346906]

vagrant@vagrant:/tmp/new$ ls

lost+found test.gz
```

14. Прикрепите вывод `lsblk`.

```bash
vagrant@vagrant:/tmp/new$ lsblk

NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT

loop0 7:0 0 55.4M 1 loop /snap/core18/2128

loop2 7:2 0 70.3M 1 loop /snap/lxd/21029

loop3 7:3 0 55.5M 1 loop /snap/core18/2284

loop4 7:4 0 43.6M 1 loop /snap/snapd/14978

loop5 7:5 0 61.9M 1 loop /snap/core20/1328

loop6 7:6 0 67.2M 1 loop /snap/lxd/21835

sda 8:0 0 64G 0 disk

├─sda1 8:1 0 1M 0 part

├─sda2 8:2 0 1G 0 part /boot

└─sda3 8:3 0 63G 0 part

└─ubuntu--vg-ubuntu--lv 253:0 0 31.5G 0 lvm /

sdb 8:16 0 2.5G 0 disk

├─sdb1 8:17 0 2G 0 part

│ └─md0 9:0 0 2G 0 raid1

└─sdb2 8:18 0 511M 0 part

└─md1 9:1 0 1018M 0 raid0

└─netology-netology--lv 253:1    0  100M  0 lvm   /tmp/new
sdc 8:32 0 2.5G 0 disk

├─sdc1 8:33 0 2G 0 part

│ └─md0 9:0 0 2G 0 raid1

└─sdc2 8:34 0 511M 0 part

└─md1 9:1 0 1018M 0 raid0

└─netology-netology--lv 253:1    0  100M  0 lvm   /tmp/new
```

15. Протестируйте целостность файла:

    ```bash
    root@vagrant:~# gzip -t /tmp/new/test.gz
    root@vagrant:~# echo $?
    0
    ```

```bash
vagrant@vagrant:/tmp/new$ gzip -t /tmp/new/test.gz

vagrant@vagrant:/tmp/new$ echo?

0
```

16. Используя pvmove, переместите содержимое `PV` с RAID0 на RAID1.

```bash
vagrant@vagrant:/tmp/new$ sudo pvmove -n netology-lv /dev/md1 /dev/md0

/dev/md1: Moved: 12.00%

/dev/md1: Moved: 100.00%

vagrant@vagrant:/tmp/new$ sudo lvs -o +devices

LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert Devices

netology-lv netology -wi-ao---- 100.00m /dev/md0(0)

ubuntu-lv ubuntu-vg -wi-ao---- 31.50g /dev/sda3(0)
```

17. Сделайте `--fail` на устройство в вашем RAID1 md.

```bash
vagrant@vagrant:~$ sudo mdadm --fail /dev/md0 /dev/sdb1

mdadm: set /dev/sdb1 faulty in /dev/md0
```

18. Подтвердите выводом `dmesg`, что RAID1 работает в деградированном состоянии.

```bash
vagrant@vagrant:~$ sudo dmesg | grep md0

[24010.210413] md/raid1:md0: not clean -- starting background reconstruction

[24010.210417] md/raid1:md0: active with 2 out of 2 mirrors

[24010.210478] md0: detected capacity change from 0 to 2144337920

[24010.212729] md: resync of RAID array md0

[24027.614837] md: md0: resync done.

[25373.401990] md/raid1:md0: Disk failure on sdb1, disabling device.

           md/raid1:md0: Operation continuing on 1 devices.
```

19. Протестируйте целостность файла, несмотря на "сбойный" диск он должен продолжать быть доступен:

    ```bash
    root@vagrant:~# gzip -t /tmp/new/test.gz
    root@vagrant:~# echo $?
    0
    ```

```bash
vagrant@vagrant:/tmp/new$ gzip -t /tmp/new/test.gz

vagrant@vagrant:/tmp/new$ echo?

0
```

20. Погасите тестовый хост, `vagrant destroy`.

```bash
lsd@nucub:~/vagrant$ vagrant destroy

default: Are you sure you want to destroy the 'default' VM? [y/N] y
==> default: Forcing shutdown of VM...

==> default: Destroying VM and associated drives...
```